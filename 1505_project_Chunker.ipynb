{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1nTAPOr3rDTlPi6a8mFBzdjAqJi8JTIC3",
      "authorship_tag": "ABX9TyMJzdcHhwNXz/Q/HDD/tB1J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehmetbozdemir24/Tubitak_1505_Proje/blob/chunking/1505_project_Chunker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jluZ5iWvX_cZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e133f12-eca4-4120-e679-bb70171e76b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gerekli kütüphaneler kuruluyor... Lütfen bekleyin.\n",
            "Kurulum tamamlandı.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import pickle\n",
        "import subprocess\n",
        "import re\n",
        "\n",
        "# Gerekli paketlerin kontrolü ve kurulumu\n",
        "def install_packages():\n",
        "    print(\"Gerekli kütüphaneler kuruluyor... Lütfen bekleyin.\")\n",
        "    packages = [\n",
        "        \"langchain\",\n",
        "        \"langchain-community\",\n",
        "        \"pypdf\",\n",
        "        \"openpyxl\",\n",
        "        \"pandas\",\n",
        "        \"python-docx\",\n",
        "        \"python-pptx\",\n",
        "        \"unstructured\",\n",
        "        \"networkx\"\n",
        "    ]\n",
        "    try:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\"] + packages)\n",
        "        print(\"Kurulum tamamlandı.\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Kurulum sırasında bir hata oluştu: {e}\")\n",
        "        # Optionally re-raise or handle more gracefully\n",
        "\n",
        "try:\n",
        "    import langchain\n",
        "    import pandas as pd\n",
        "    from docx import Document as DocxDocument\n",
        "    from langchain_community.document_loaders import (\n",
        "        PyPDFLoader,\n",
        "        UnstructuredPowerPointLoader\n",
        "    )\n",
        "    from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "    from langchain_core.documents import Document\n",
        "except ImportError:\n",
        "    install_packages()\n",
        "    # Re-attempt imports after installation\n",
        "    import langchain\n",
        "    import pandas as pd\n",
        "    from docx import Document as DocxDocument\n",
        "    from langchain_community.document_loaders import (\n",
        "        PyPDFLoader,\n",
        "        UnstructuredPowerPointLoader\n",
        "    )\n",
        "    from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "    from langchain_core.documents import Document\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_PATH = \"/content/drive/MyDrive/1505 Chunking/Doküman\"\n",
        "TARGET_FOLDERS = [\"pdf\", \"excel\", \"word\", \"powerpoint\"]\n"
      ],
      "metadata": {
        "id": "qGVccdPMYU3z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_permission_from_content(text_content):\n",
        "\n",
        "    text_lower = text_content.lower()[:5000]\n",
        "\n",
        "    # 1. Seviye: Admin\n",
        "    admin_keywords = [\"gizli\", \"confidential\", \"passwords\", \"şifreler\", \"yönetim kurulu\", \"admin only\"]\n",
        "    if any(k in text_lower for k in admin_keywords):\n",
        "        return \"admin\"\n",
        "\n",
        "    # 2. Seviye: Manager\n",
        "    manager_keywords = [\"maliyet\", \"bütçe\", \"budget\", \"finans\", \"salary\", \"maaş\", \"forecast\"]\n",
        "    if any(k in text_lower for k in manager_keywords):\n",
        "        return \"manager\"\n",
        "\n",
        "    # 3. Seviye: Editor\n",
        "    editor_keywords = [\"taslak\", \"draft\", \"düzenlenecek\", \"teknik şartname\"]\n",
        "    if any(k in text_lower for k in editor_keywords):\n",
        "        return \"editor\"\n",
        "\n",
        "    # Varsayılan: User\n",
        "    return \"user\"\n",
        "\n"
      ],
      "metadata": {
        "id": "X4uCvwgYYh1d"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DriveDocumentProcessor:\n",
        "    def __init__(self, chunk_size=1000, chunk_overlap=100):\n",
        "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=chunk_size,\n",
        "            chunk_overlap=chunk_overlap\n",
        "        )\n",
        "        self.processed_chunks = []\n",
        "\n",
        "    def process_excel(self, file_path):\n",
        "\n",
        "        try:\n",
        "            xls = pd.read_excel(file_path, sheet_name=None)\n",
        "            filename = os.path.basename(file_path)\n",
        "\n",
        "            for sheet_name, df in xls.items():\n",
        "                df.dropna(how='all', axis=0, inplace=True)\n",
        "                df.dropna(how='all', axis=1, inplace=True)\n",
        "\n",
        "                for col in df.columns:\n",
        "                    if pd.api.types.is_datetime64_any_dtype(df[col]):\n",
        "                        df[col] = df[col].dt.strftime('%Y-%m-%d')\n",
        "\n",
        "                sheet_content_sample = df.to_string()\n",
        "                permission = detect_permission_from_content(sheet_content_sample)\n",
        "\n",
        "                columns = df.columns.tolist()\n",
        "\n",
        "                for index, row in df.iterrows():\n",
        "                    row_data = []\n",
        "                    for col in columns:\n",
        "                        val = row[col]\n",
        "                        if pd.notna(val) and str(val).strip() != \"\":\n",
        "                            row_data.append(f\"{col}: {val}\")\n",
        "\n",
        "                    if not row_data: continue\n",
        "\n",
        "                    row_text = (\n",
        "                        f\"KAYNAK: {filename} > {sheet_name}\\n\"\n",
        "                        f\"SATIR ID: {index+1}\\n\"\n",
        "                        f\"VERİLER:\\n\" + \"\\n\".join(row_data)\n",
        "                    )\n",
        "\n",
        "                    metadata = {\n",
        "                        \"source\": filename,\n",
        "                        \"sheet\": sheet_name,\n",
        "                        \"row\": index + 1,\n",
        "                        \"type\": \"excel_row\",\n",
        "                        \"permission\": permission,\n",
        "                        \"columns_present\": list(columns)\n",
        "                    }\n",
        "\n",
        "                    self.processed_chunks.append(Document(page_content=row_text, metadata=metadata))\n",
        "\n",
        "            print(f\"  -> Excel işlendi: {filename} ({len(xls)} sayfa)\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  !! Excel hatası ({os.path.basename(file_path)}): {e}\")\n",
        "\n",
        "    def process_word_detailed(self, file_path):\n",
        "        \"\"\"\n",
        "        Word dosyasını açar, paragrafları ayrı, tabloları ayrı işler.\n",
        "        Tabloları Excel mantığıyla satır satır anlamlandırır.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            doc = DocxDocument(file_path)\n",
        "            filename = os.path.basename(file_path)\n",
        "\n",
        "            full_text = \"\\n\".join([p.text for p in doc.paragraphs])\n",
        "            permission = detect_permission_from_content(full_text)\n",
        "\n",
        "            text_content = []\n",
        "            for para in doc.paragraphs:\n",
        "                if para.text.strip():\n",
        "                    text_content.append(para.text)\n",
        "\n",
        "            if text_content:\n",
        "                raw_text = \"\\n\".join(text_content)\n",
        "                text_chunks = self.text_splitter.create_documents([raw_text])\n",
        "                for chunk in text_chunks:\n",
        "                    chunk.metadata.update({\n",
        "                        \"source\": filename,\n",
        "                        \"type\": \"word_text\",\n",
        "                        \"permission\": permission\n",
        "                    })\n",
        "                    self.processed_chunks.append(chunk)\n",
        "\n",
        "            for i, table in enumerate(doc.tables):\n",
        "\n",
        "                if not table.rows: continue\n",
        "\n",
        "                headers = [cell.text.strip() for cell in table.rows[0].cells]\n",
        "\n",
        "                if all(h == \"\" for h in headers):\n",
        "                    headers = [f\"Sütun_{k+1}\" for k in range(len(headers))]\n",
        "\n",
        "                for j, row in enumerate(table.rows[1:], start=1):\n",
        "                    row_content = []\n",
        "                    for k, cell in enumerate(row.cells):\n",
        "                        if k < len(headers):\n",
        "                            key = headers[k]\n",
        "                            val = cell.text.strip()\n",
        "                            if val:\n",
        "                                row_content.append(f\"{key}: {val}\")\n",
        "\n",
        "                    if row_content:\n",
        "\n",
        "                        table_text = (\n",
        "                            f\"BELGE: {filename} > TABLO_{i+1}\\n\"\n",
        "                            f\"SATIR: {j}\\n\"\n",
        "                            f\"İÇERİK:\\n\" + \"\\n\".join(row_content)\n",
        "                        )\n",
        "\n",
        "                        meta = {\n",
        "                            \"source\": filename,\n",
        "                            \"type\": \"word_table\",\n",
        "                            \"table_id\": i+1,\n",
        "                            \"row_id\": j,\n",
        "                            \"permission\": permission\n",
        "                        }\n",
        "                        self.processed_chunks.append(Document(page_content=table_text, metadata=meta))\n",
        "\n",
        "            print(f\"  -> Word detaylı işlendi: {filename}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  !! Word hatası ({filename}): {e}\")\n",
        "\n",
        "    def process_powerpoint_pdf(self, file_path, file_type):\n",
        "        loader = None\n",
        "        try:\n",
        "            if file_type == \"pdf\":\n",
        "                loader = PyPDFLoader(file_path)\n",
        "            elif file_type == \"powerpoint\":\n",
        "                loader = UnstructuredPowerPointLoader(file_path)\n",
        "\n",
        "            if not loader: return\n",
        "\n",
        "            raw_docs = loader.load()\n",
        "\n",
        "            # İçerikten yetki analizi\n",
        "            full_sample_text = \" \".join([d.page_content for d in raw_docs[:5]])\n",
        "            permission = detect_permission_from_content(full_sample_text)\n",
        "\n",
        "            chunks = self.text_splitter.split_documents(raw_docs)\n",
        "            filename = os.path.basename(file_path)\n",
        "\n",
        "            for chunk in chunks:\n",
        "                page = chunk.metadata.get(\"page\", chunk.metadata.get(\"page_number\", 1))\n",
        "                chunk.metadata.update({\n",
        "                    \"source\": filename,\n",
        "                    \"permission\": permission,\n",
        "                    \"file_type\": file_type\n",
        "                })\n",
        "                self.processed_chunks.append(chunk)\n",
        "\n",
        "            print(f\"  -> {file_type.upper()} işlendi: {len(chunks)} parça. (Yetki: {permission})\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  !! Hata ({file_type} - {os.path.basename(file_path)}): {e}\")\n",
        "\n",
        "    def save_data(self, output_path):\n",
        "        with open(output_path, \"wb\") as f:\n",
        "            pickle.dump(self.processed_chunks, f)\n",
        "        print(f\"\\nToplam {len(self.processed_chunks)} chunk kaydedildi: {output_path}\")\n"
      ],
      "metadata": {
        "id": "wfEsKSFNYsdQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    processor = DriveDocumentProcessor()\n",
        "    print(f\"Tarama Başlıyor: {BASE_PATH}\")\n",
        "\n",
        "    if not os.path.exists(BASE_PATH):\n",
        "        print(f\"HATA: Belirtilen yol bulunamadı! -> {BASE_PATH}\")\n",
        "\n",
        "        return\n",
        "\n",
        "    for folder in TARGET_FOLDERS:\n",
        "        folder_path = os.path.join(BASE_PATH, folder)\n",
        "        if not os.path.exists(folder_path):\n",
        "            print(f\"Uyarı: Klasör yok -> {folder}\")\n",
        "            continue\n",
        "\n",
        "        print(f\"\\n[{folder.upper()}] Klasörü Taranıyor...\")\n",
        "        files = os.listdir(folder_path)\n",
        "\n",
        "        for filename in files:\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "\n",
        "            # Gizli dosyaları atla\n",
        "            if filename.startswith(\".\"): continue\n",
        "\n",
        "            # Dosya türüne göre işlem\n",
        "            if folder == \"excel\" and (filename.endswith(\".xlsx\") or filename.endswith(\".xls\")):\n",
        "                processor.process_excel(file_path)\n",
        "\n",
        "            elif folder == \"word\" and (filename.endswith(\".docx\") or filename.endswith(\".doc\")):\n",
        "                processor.process_word_detailed(file_path)\n",
        "\n",
        "            elif folder == \"pdf\" and filename.endswith(\".pdf\"):\n",
        "                processor.process_powerpoint_pdf(file_path, \"pdf\")\n",
        "\n",
        "            elif folder == \"powerpoint\" and (filename.endswith(\".pptx\") or filename.endswith(\".ppt\")):\n",
        "                processor.process_powerpoint_pdf(file_path, \"powerpoint\")\n",
        "\n",
        "    output_file = \"/content/drive/MyDrive/1505 Chunking/tum_dokumanlar_final.pkl\"\n",
        "\n",
        "    if not os.path.exists(os.path.dirname(output_file)):\n",
        "        output_file = \"tum_dokumanlar_final.pkl\"\n",
        "\n",
        "    processor.save_data(output_file)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gw9Q2LqMZWt2",
        "outputId": "fd16959b-f1a7-49c2-c983-f5aefbc290e7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tarama Başlıyor: /content/drive/MyDrive/1505 Chunking/Doküman\n",
            "\n",
            "[PDF] Klasörü Taranıyor...\n",
            "  -> PDF işlendi: 67 parça. (Yetki: user)\n",
            "  -> PDF işlendi: 53 parça. (Yetki: manager)\n",
            "  -> PDF işlendi: 24 parça. (Yetki: user)\n",
            "  -> PDF işlendi: 103 parça. (Yetki: user)\n",
            "  -> PDF işlendi: 13 parça. (Yetki: user)\n",
            "  -> PDF işlendi: 51 parça. (Yetki: user)\n",
            "  -> PDF işlendi: 44 parça. (Yetki: user)\n",
            "  -> PDF işlendi: 21 parça. (Yetki: admin)\n",
            "  -> PDF işlendi: 27 parça. (Yetki: admin)\n",
            "  -> PDF işlendi: 22 parça. (Yetki: user)\n",
            "  -> PDF işlendi: 5 parça. (Yetki: admin)\n",
            "  -> PDF işlendi: 7 parça. (Yetki: admin)\n",
            "  -> PDF işlendi: 35 parça. (Yetki: user)\n",
            "  -> PDF işlendi: 7 parça. (Yetki: admin)\n",
            "  -> PDF işlendi: 14 parça. (Yetki: user)\n",
            "  -> PDF işlendi: 5 parça. (Yetki: user)\n",
            "  -> PDF işlendi: 15 parça. (Yetki: user)\n",
            "  -> PDF işlendi: 7 parça. (Yetki: user)\n",
            "  -> PDF işlendi: 5 parça. (Yetki: user)\n",
            "  -> PDF işlendi: 3 parça. (Yetki: user)\n",
            "  -> PDF işlendi: 3 parça. (Yetki: user)\n",
            "  -> PDF işlendi: 4 parça. (Yetki: user)\n",
            "  -> PDF işlendi: 2 parça. (Yetki: user)\n",
            "  -> PDF işlendi: 2 parça. (Yetki: user)\n",
            "  -> PDF işlendi: 2 parça. (Yetki: user)\n",
            "  -> PDF işlendi: 2 parça. (Yetki: user)\n",
            "  -> PDF işlendi: 3 parça. (Yetki: user)\n",
            "  -> PDF işlendi: 4 parça. (Yetki: user)\n",
            "  -> PDF işlendi: 6 parça. (Yetki: user)\n",
            "  -> PDF işlendi: 26 parça. (Yetki: admin)\n",
            "  -> PDF işlendi: 5 parça. (Yetki: user)\n",
            "  -> PDF işlendi: 4 parça. (Yetki: user)\n",
            "  -> PDF işlendi: 9 parça. (Yetki: admin)\n",
            "\n",
            "[EXCEL] Klasörü Taranıyor...\n",
            "  -> Excel işlendi: Bilimp_Fiyat_Listesi_Ornek_Sablon2.xlsx (1 sayfa)\n",
            "  -> Excel işlendi: Bilimp_Fiyat_Listesi_Ornek_Sablon.xlsx (1 sayfa)\n",
            "  -> Excel işlendi: Aylik_Satis_Ozet_Ornek_Sablon.xlsx (1 sayfa)\n",
            "\n",
            "[WORD] Klasörü Taranıyor...\n",
            "  -> Word detaylı işlendi: Haftalik_Yemek_Listesi.docx\n",
            "  -> Word detaylı işlendi: Gizli_Erisim_Bilgileri.docx\n",
            "  -> Word detaylı işlendi: Teknik_Sartname_Taslak.docx\n",
            "  -> Word detaylı işlendi: Butce_Ve_Maliyet_Raporu.docx\n",
            "\n",
            "[POWERPOINT] Klasörü Taranıyor...\n",
            "  -> POWERPOINT işlendi: 3 parça. (Yetki: user)\n",
            "\n",
            "Toplam 777 chunk kaydedildi: /content/drive/MyDrive/1505 Chunking/tum_dokumanlar_final.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*view-chunker*"
      ],
      "metadata": {
        "id": "bw5voY5laEcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import pickle\n"
      ],
      "metadata": {
        "id": "FmzY61B81VNF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from langchain_core.documents import Document\n",
        "except ImportError:\n",
        "    import subprocess\n",
        "    print(\"Gerekli kütüphane (langchain) kuruluyor...\")\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"langchain\", \"langchain-community\", \"langchain-core\"])\n",
        "    from langchain_core.documents import Document\n",
        "\n",
        "POSSIBLE_PATHS = [\n",
        "    \"/content/drive/MyDrive/1505 Chunking/tum_dokumanlar_final.pkl\",\n",
        "]\n",
        "\n",
        "def find_file():\n",
        "    for path in POSSIBLE_PATHS:\n",
        "        if os.path.exists(path):\n",
        "            return path\n",
        "    return None\n",
        "\n",
        "def preview_data(file_path):\n",
        "    print(f\" Yüklenen Dosya: {file_path}\")\n",
        "\n",
        "    try:\n",
        "        with open(file_path, \"rb\") as f:\n",
        "            chunks = pickle.load(f)\n",
        "    except Exception as e:\n",
        "        print(f\"HATA: Dosya okunamadı. {e}\")\n",
        "        return\n",
        "\n",
        "    total_count = len(chunks)\n",
        "    print(f\" Başarıyla Yüklendi! Toplam Chunk Sayısı: {total_count}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Türlere göre grupla\n",
        "    target_types = [\"pdf\", \"excel\", \"word\", \"powerpoint\"]\n",
        "    samples = {t: [] for t in target_types}\n",
        "\n",
        "    for chunk in chunks:\n",
        "        ftype = chunk.metadata.get(\"file_type\")\n",
        "\n",
        "        if not ftype:\n",
        "            source = chunk.metadata.get(\"source\", \"\").lower()\n",
        "            if source.endswith(\".docx\") or source.endswith(\".doc\"):\n",
        "                ftype = \"word\"\n",
        "            elif source.endswith(\".xlsx\") or source.endswith(\".xls\"):\n",
        "                ftype = \"excel\"\n",
        "            elif source.endswith(\".pdf\"):\n",
        "                ftype = \"pdf\"\n",
        "            elif source.endswith(\".pptx\") or source.endswith(\".ppt\"):\n",
        "                ftype = \"powerpoint\"\n",
        "            else:\n",
        "                ftype = \"unknown\"\n",
        "\n",
        "        if ftype in samples and len(samples[ftype]) < 3:\n",
        "            samples[ftype].append(chunk)\n",
        "\n",
        "    print(f\"\\n>>> Dosya Türü Bazlı Örnekler\")\n",
        "\n",
        "    for ftype in target_types:\n",
        "        items = samples.get(ftype, [])\n",
        "        print(f\"\\n--- TÜR: {ftype.upper()} ({len(items)} örnek gösteriliyor) ---\")\n",
        "\n",
        "        if not items:\n",
        "            print(\"   (Bu dosya türüne ait veri bulunamadı)\")\n",
        "            continue\n",
        "\n",
        "        for idx, item in enumerate(items):\n",
        "            if ftype == 'excel':\n",
        "                loc_label = \"Satır\"\n",
        "                loc_val = item.metadata.get('row_number', '?')\n",
        "                sheet_val = item.metadata.get('sheet', '')\n",
        "                location_info = f\"Sayfa: {sheet_val} | Satır: {loc_val}\"\n",
        "            elif ftype == 'word':\n",
        "                if item.metadata.get('type') == 'word_table':\n",
        "                    loc_label = \"Tablo ID\"\n",
        "                    loc_val = item.metadata.get('table_id', '?')\n",
        "                    location_info = f\"Tablo: {loc_val} | Satır: {item.metadata.get('row_id', '?')}\"\n",
        "                else:\n",
        "                    location_info = \"Düz Metin\"\n",
        "            else:\n",
        "                loc_label = \"Sayfa\"\n",
        "                loc_val = item.metadata.get('page_number', item.metadata.get('page', '?'))\n",
        "                location_info = f\"Sayfa: {loc_val}\"\n",
        "\n",
        "            src = item.metadata.get('source')\n",
        "            perm = item.metadata.get('permission', 'Yok')\n",
        "\n",
        "            text = item.page_content.replace('\\n', ' ')[:200]\n",
        "\n",
        "            print(f\"{idx+1}. Kaynak: {src}\")\n",
        "            print(f\"   Konum : {location_info}\")\n",
        "            print(f\"   Yetki : {perm}\")\n",
        "            print(f\"   İçerik: {text}...\")\n",
        "            print(\"-\" * 40)\n",
        "\n",
        "found_path = find_file()\n",
        "\n",
        "if found_path:\n",
        "    preview_data(found_path)\n",
        "else:\n",
        "    print(\"HATA: Hiçbir .pkl dosyası bulunamadı!\")\n",
        "    print(\"Lütfen chunk işleminin başarıyla tamamlandığından ve dosyanın Drive'a kaydedildiğinden emin olun.\")\n",
        "    print(\"Aranan yollar:\")\n",
        "    for p in POSSIBLE_PATHS:\n",
        "        print(f\" - {p}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvR7rp5b1WiA",
        "outputId": "89fd49d3-29ca-4e1f-b2b0-b1cbab914817"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Yüklenen Dosya: /content/drive/MyDrive/1505 Chunking/tum_dokumanlar_final.pkl\n",
            " Başarıyla Yüklendi! Toplam Chunk Sayısı: 777\n",
            "============================================================\n",
            "\n",
            ">>> Dosya Türü Bazlı Örnekler\n",
            "\n",
            "--- TÜR: PDF (3 örnek gösteriliyor) ---\n",
            "1. Kaynak: 207858.pdf\n",
            "   Konum : Sayfa: 0\n",
            "   Yetki : user\n",
            "   İçerik: Senato Karar Eki    BURSA ULUDAĞ ÜNİVERSİTESİ İŞ SAĞLIĞI VE GÜVENLİĞİ YÖNERGESİ  BİRİNCİ BÖLÜM  Amaç, Kapsam, Dayanak ve Tanımlar  Amaç  MADDE 1- (1) Bu Yönerge’nin amacı, 6331 sayılı İş Sağlığı ve Gü...\n",
            "----------------------------------------\n",
            "2. Kaynak: 207858.pdf\n",
            "   Konum : Sayfa: 0\n",
            "   Yetki : user\n",
            "   İçerik: Tanımlar  MADDE 4- (1) Bu Yönerge’de geçen,  a) Acil durum: İşyerinin tamamında veya bir kısmında meydana gelebilecek yangın,  patlama, tehlikeli kimyasal maddelerden kaynaklanan yayılım, doğal afet g...\n",
            "----------------------------------------\n",
            "3. Kaynak: 207858.pdf\n",
            "   Konum : Sayfa: 0\n",
            "   Yetki : user\n",
            "   İçerik: d) Birim: Bir işyeri sosyal güvenlik sicil numarası ve/veya birim NACE kod numarasına  sahip olup İş Sağlığı ve Güvenliği (İSG) mevzuatında işyeri olarak kabul gören Bursa Uludağ  Üniversitesi’ne bağl...\n",
            "----------------------------------------\n",
            "\n",
            "--- TÜR: EXCEL (3 örnek gösteriliyor) ---\n",
            "1. Kaynak: Bilimp_Fiyat_Listesi_Ornek_Sablon2.xlsx\n",
            "   Konum : Sayfa: Fiyat Listesi | Satır: ?\n",
            "   Yetki : user\n",
            "   İçerik: KAYNAK: Bilimp_Fiyat_Listesi_Ornek_Sablon2.xlsx > Fiyat Listesi SATIR ID: 1 VERİLER: Ürün Kodu: BIL-25-001 Ürün Adı: Bilimp CRM Modülü Kategori: Yazılım Lisansı Birim: Kullanıcı Liste Fiyatı: 5082 İnd...\n",
            "----------------------------------------\n",
            "2. Kaynak: Bilimp_Fiyat_Listesi_Ornek_Sablon2.xlsx\n",
            "   Konum : Sayfa: Fiyat Listesi | Satır: ?\n",
            "   Yetki : user\n",
            "   İçerik: KAYNAK: Bilimp_Fiyat_Listesi_Ornek_Sablon2.xlsx > Fiyat Listesi SATIR ID: 2 VERİLER: Ürün Kodu: BIL-25-002 Ürün Adı: Bilimp Proje Yönetimi Kategori: Yazılım Lisansı Birim: Kullanıcı Liste Fiyatı: 1314...\n",
            "----------------------------------------\n",
            "3. Kaynak: Bilimp_Fiyat_Listesi_Ornek_Sablon2.xlsx\n",
            "   Konum : Sayfa: Fiyat Listesi | Satır: ?\n",
            "   Yetki : user\n",
            "   İçerik: KAYNAK: Bilimp_Fiyat_Listesi_Ornek_Sablon2.xlsx > Fiyat Listesi SATIR ID: 3 VERİLER: Ürün Kodu: BIL-25-003 Ürün Adı: Bilimp Stok & Envanter Kategori: Yazılım Lisansı Birim: Kullanıcı Liste Fiyatı: 137...\n",
            "----------------------------------------\n",
            "\n",
            "--- TÜR: WORD (3 örnek gösteriliyor) ---\n",
            "1. Kaynak: Haftalik_Yemek_Listesi.docx\n",
            "   Konum : Düz Metin\n",
            "   Yetki : user\n",
            "   İçerik: Haftalık Şirket Duyuruları ve Yemek Listesi Genel Duyurular Değerli Çalışma Arkadaşlarımız, Şirket içi iletişimi artırmak amacıyla düzenlediğimiz 'Cuma Kahve Molaları' etkinliği bu hafta da devam edec...\n",
            "----------------------------------------\n",
            "2. Kaynak: Haftalik_Yemek_Listesi.docx\n",
            "   Konum : Tablo: 1 | Satır: 1\n",
            "   Yetki : user\n",
            "   İçerik: BELGE: Haftalik_Yemek_Listesi.docx > TABLO_1 SATIR: 1 İÇERİK: Gün: Pazartesi Ana Yemek: Kuru Fasulye & Pilav Tatlı/Meyve: Mevsim Salatası...\n",
            "----------------------------------------\n",
            "3. Kaynak: Haftalik_Yemek_Listesi.docx\n",
            "   Konum : Tablo: 1 | Satır: 2\n",
            "   Yetki : user\n",
            "   İçerik: BELGE: Haftalik_Yemek_Listesi.docx > TABLO_1 SATIR: 2 İÇERİK: Gün: Salı Ana Yemek: Izgara Tavuk & Püre Tatlı/Meyve: Fırın Sütlaç...\n",
            "----------------------------------------\n",
            "\n",
            "--- TÜR: POWERPOINT (3 örnek gösteriliyor) ---\n",
            "1. Kaynak: Bilimp_Satis_Sunum_Ornek_Sablon.pptx\n",
            "   Konum : Sayfa: ?\n",
            "   Yetki : user\n",
            "   İçerik: Bilimp Öneri Aracı  © Bilimp Yazılım 2020    Rekabet koşullarının ağırlığı  şirketleri sürekli daha iyi olmaya yani sürekli iyileşmeye zorlamaktadır.  Bu süreçte işin birebir içinde olan çalışanlardan...\n",
            "----------------------------------------\n",
            "2. Kaynak: Bilimp_Satis_Sunum_Ornek_Sablon.pptx\n",
            "   Konum : Sayfa: ?\n",
            "   Yetki : user\n",
            "   İçerik: Çalışan memnuniyetini ve bağlılığını artırır  Kazan kazan ilkesi ile motivasyonu artırır  © Bilimp Yazılım 2020    Öneri Kayıt  Çalışanlar veya dış kullanıcılar mobil uygulamayı kullanarak veya web ar...\n",
            "----------------------------------------\n",
            "3. Kaynak: Bilimp_Satis_Sunum_Ornek_Sablon.pptx\n",
            "   Konum : Sayfa: ?\n",
            "   Yetki : user\n",
            "   İçerik: © Bilimp Yazılım 2020    Bilimp’i keşfedin.  Dijital yaşamın kolaylıklarını Bilimp ile keşfetmek için hemen şimdi ücretsiz deneyin.  www.bilimp.com  © Bilimp Yazılım 2020...\n",
            "----------------------------------------\n"
          ]
        }
      ]
    }
  ]
}