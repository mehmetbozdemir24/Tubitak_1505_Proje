{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "mount_file_id": "1nTAPOr3rDTlPi6a8mFBzdjAqJi8JTIC3",
   "authorship_tag": "ABX9TyMJzdcHhwNXz/Q/HDD/tB1J",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mehmetbozdemir24/Tubitak_1505_Proje/blob/chunking/1505_project_Chunker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T15:37:08.384503Z",
     "start_time": "2025-12-06T15:37:08.372191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "# Gerekli paketlerin kontrolü ve kurulumu\n",
    "def install_packages():\n",
    "    print(\"Gerekli kütüphaneler kuruluyor... Lütfen bekleyin.\")\n",
    "    packages = [\n",
    "        \"langchain\",\n",
    "        \"langchain-community\",\n",
    "        \"pypdf\",\n",
    "        \"openpyxl\",\n",
    "        \"pandas\",\n",
    "        \"python-docx\",\n",
    "        \"python-pptx\",\n",
    "        \"unstructured\",\n",
    "        \"networkx\"\n",
    "    ]\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\"] + packages)\n",
    "        print(\"Kurulum tamamlandı.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Kurulum sırasında bir hata oluştu: {e}\")\n",
    "        # Optionally re-raise or handle more gracefully\n",
    "\n",
    "try:\n",
    "    import langchain\n",
    "    import pandas as pd\n",
    "    from docx import Document as DocxDocument\n",
    "    from langchain_community.document_loaders import (\n",
    "        PyPDFLoader,\n",
    "        UnstructuredPowerPointLoader\n",
    "    )\n",
    "    from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "    from langchain_core.documents import Document\n",
    "except ImportError:\n",
    "    install_packages()\n",
    "    # Re-attempt imports after installation\n",
    "    import langchain\n",
    "    import pandas as pd\n",
    "    from docx import Document as DocxDocument\n",
    "    from langchain_community.document_loaders import (\n",
    "        PyPDFLoader,\n",
    "        UnstructuredPowerPointLoader\n",
    "    )\n",
    "    from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "    from langchain_core.documents import Document\n"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T15:37:09.350423Z",
     "start_time": "2025-12-06T15:37:09.339992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "# Kodun çalıştığı klasör (C:\\mebi\\Tubitak_1505_Proje)\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# HATA BURADAYDI: project_root = os.path.dirname(current_dir) yapınca C:\\mebi'ye çıkıyordu.\n",
    "# DÜZELTME: Olduğumuz yer zaten proje ana klasörü, yukarı çıkma.\n",
    "project_root = current_dir\n",
    "\n",
    "# Doküman klasörünün yolu\n",
    "BASE_PATH = os.path.join(project_root, \"Doküman\")\n",
    "TARGET_FOLDERS = [\"pdf\", \"excel\", \"word\", \"powerpoint\"]\n",
    "\n",
    "print(f\"Şu anki konum: {current_dir}\")\n",
    "print(f\"Hedef klasör (BASE_PATH): {BASE_PATH}\")\n",
    "\n",
    "# Main fonksiyonu içindeki output_file kısmını da buna göre güncellemelisin:\n",
    "# output_file = os.path.join(project_root, \"tum_dokumanlar_final_last.pkl\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Şu anki konum: C:\\mebi\\Tubitak_1505_Proje\n",
      "Hedef klasör (BASE_PATH): C:\\mebi\\Tubitak_1505_Proje\\Doküman\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "source": [
    "def detect_permission_from_content(text_content):\n",
    "\n",
    "    text_lower = text_content.lower()[:5000]\n",
    "\n",
    "    # 1. Seviye: Admin\n",
    "    admin_keywords = [\"gizli\", \"confidential\", \"passwords\", \"şifreler\", \"yönetim kurulu\", \"admin only\"]\n",
    "    if any(k in text_lower for k in admin_keywords):\n",
    "        return \"admin\"\n",
    "\n",
    "    # 2. Seviye: Manager\n",
    "    manager_keywords = [\"maliyet\", \"bütçe\", \"budget\", \"finans\", \"salary\", \"maaş\", \"forecast\"]\n",
    "    if any(k in text_lower for k in manager_keywords):\n",
    "        return \"manager\"\n",
    "\n",
    "    # 3. Seviye: Editor\n",
    "    editor_keywords = [\"taslak\", \"draft\", \"düzenlenecek\", \"teknik şartname\"]\n",
    "    if any(k in text_lower for k in editor_keywords):\n",
    "        return \"editor\"\n",
    "\n",
    "    # Varsayılan: User\n",
    "    return \"user\"\n",
    "\n"
   ],
   "metadata": {
    "id": "X4uCvwgYYh1d",
    "ExecuteTime": {
     "end_time": "2025-12-06T15:37:09.975719Z",
     "start_time": "2025-12-06T15:37:09.968288Z"
    }
   },
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "source": [
    "class DriveDocumentProcessor:\n",
    "    def __init__(self, chunk_size=1000, chunk_overlap=100):\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap\n",
    "        )\n",
    "        self.processed_chunks = []\n",
    "\n",
    "    def process_excel(self, file_path):\n",
    "        \"\"\"\n",
    "        Excel dosyasındaki her sayfayı tek bir Markdown tablosu olarak işler.\n",
    "        Böylece LLM tablo bütünlüğünü görerek matematiksel işlemler yapabilir.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Excel dosyasını oku\n",
    "            xls = pd.read_excel(file_path, sheet_name=None)\n",
    "            filename = os.path.basename(file_path)\n",
    "\n",
    "            for sheet_name, df in xls.items():\n",
    "                # 1. Boş satır ve sütunları temizle\n",
    "                df.dropna(how='all', axis=0, inplace=True)\n",
    "                df.dropna(how='all', axis=1, inplace=True)\n",
    "\n",
    "                # 2. Tarih formatlarını düzelt (datetime objelerini string'e çevir)\n",
    "                for col in df.columns:\n",
    "                    if pd.api.types.is_datetime64_any_dtype(df[col]):\n",
    "                        df[col] = df[col].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "                # 3. VERİYİ MARKDOWN TABLOYA ÇEVİR (En kritik adım burası)\n",
    "                # index=False diyerek gereksiz satır numaralarını (0,1,2...) almiyoruz.\n",
    "                try:\n",
    "                    markdown_table = df.to_markdown(index=False)\n",
    "                except ImportError:\n",
    "                    print(\"HATA: 'tabulate' kütüphanesi eksik. Lütfen 'pip install tabulate' çalıştırın.\")\n",
    "                    return\n",
    "\n",
    "                # Yetki analizi (tablo içeriğine göre)\n",
    "                permission = detect_permission_from_content(markdown_table)\n",
    "\n",
    "                # 4. Tek bir Chunk oluştur (Bütün tablo tek parça)\n",
    "                table_text = (\n",
    "                    f\"KAYNAK: {filename} > {sheet_name}\\n\"\n",
    "                    f\"TÜR: Excel Tablosu\\n\"\n",
    "                    f\"İÇERİK:\\n\"\n",
    "                    f\"{markdown_table}\"\n",
    "                )\n",
    "\n",
    "                metadata = {\n",
    "                    \"source\": filename,\n",
    "                    \"sheet\": sheet_name,\n",
    "                    \"file_type\": \"excel\", # Tipini değiştirdik, artık satır değil tablo.\n",
    "                    \"permission\": permission,\n",
    "                    \"columns_present\": df.columns.tolist()\n",
    "                }\n",
    "\n",
    "                # self.text_splitter kullanmıyoruz çünkü tabloyu bölmek istemiyoruz.\n",
    "                # Doğrudan listeye ekliyoruz.\n",
    "                self.processed_chunks.append(Document(page_content=table_text, metadata=metadata))\n",
    "\n",
    "            print(f\"  -> Excel Tablo formatında işlendi: {filename} ({len(xls)} sayfa)\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  !! Excel hatası ({os.path.basename(file_path)}): {e}\")\n",
    "\n",
    "    def process_word_detailed(self, file_path):\n",
    "        \"\"\"\n",
    "        Word dosyasını açar, paragrafları ayrı, tabloları ayrı işler.\n",
    "        Tabloları Excel mantığıyla satır satır anlamlandırır.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            doc = DocxDocument(file_path)\n",
    "            filename = os.path.basename(file_path)\n",
    "\n",
    "            full_text = \"\\n\".join([p.text for p in doc.paragraphs])\n",
    "            permission = detect_permission_from_content(full_text)\n",
    "\n",
    "            text_content = []\n",
    "            for para in doc.paragraphs:\n",
    "                if para.text.strip():\n",
    "                    text_content.append(para.text)\n",
    "\n",
    "            if text_content:\n",
    "                raw_text = \"\\n\".join(text_content)\n",
    "                text_chunks = self.text_splitter.create_documents([raw_text])\n",
    "                for chunk in text_chunks:\n",
    "                    chunk.metadata.update({\n",
    "                        \"source\": filename,\n",
    "                        \"file_type\": \"word\",\n",
    "                        \"permission\": permission\n",
    "                    })\n",
    "                    self.processed_chunks.append(chunk)\n",
    "\n",
    "            for i, table in enumerate(doc.tables):\n",
    "\n",
    "                if not table.rows: continue\n",
    "\n",
    "                headers = [cell.text.strip() for cell in table.rows[0].cells]\n",
    "\n",
    "                if all(h == \"\" for h in headers):\n",
    "                    headers = [f\"Sütun_{k+1}\" for k in range(len(headers))]\n",
    "\n",
    "                for j, row in enumerate(table.rows[1:], start=1):\n",
    "                    row_content = []\n",
    "                    for k, cell in enumerate(row.cells):\n",
    "                        if k < len(headers):\n",
    "                            key = headers[k]\n",
    "                            val = cell.text.strip()\n",
    "                            if val:\n",
    "                                row_content.append(f\"{key}: {val}\")\n",
    "\n",
    "                    if row_content:\n",
    "\n",
    "                        table_text = (\n",
    "                            f\"BELGE: {filename} > TABLO_{i+1}\\n\"\n",
    "                            f\"SATIR: {j}\\n\"\n",
    "                            f\"İÇERİK:\\n\" + \"\\n\".join(row_content)\n",
    "                        )\n",
    "\n",
    "                        meta = {\n",
    "                            \"source\": filename,\n",
    "                            \"type\": \"word_table\",\n",
    "                            \"table_id\": i+1,\n",
    "                            \"row_id\": j,\n",
    "                            \"permission\": permission\n",
    "                        }\n",
    "                        self.processed_chunks.append(Document(page_content=table_text, metadata=meta))\n",
    "\n",
    "            print(f\"  -> Word detaylı işlendi: {filename}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  !! Word hatası ({filename}): {e}\")\n",
    "\n",
    "    def process_powerpoint_pdf(self, file_path, file_type):\n",
    "        loader = None\n",
    "        try:\n",
    "            if file_type == \"pdf\":\n",
    "                loader = PyPDFLoader(file_path)\n",
    "            elif file_type == \"powerpoint\":\n",
    "                loader = UnstructuredPowerPointLoader(file_path)\n",
    "\n",
    "            if not loader: return\n",
    "\n",
    "            raw_docs = loader.load()\n",
    "\n",
    "            # İçerikten yetki analizi\n",
    "            full_sample_text = \" \".join([d.page_content for d in raw_docs[:5]])\n",
    "            permission = detect_permission_from_content(full_sample_text)\n",
    "\n",
    "            chunks = self.text_splitter.split_documents(raw_docs)\n",
    "            filename = os.path.basename(file_path)\n",
    "\n",
    "            for chunk in chunks:\n",
    "                page = chunk.metadata.get(\"page\", chunk.metadata.get(\"page_number\", 1))\n",
    "                chunk.metadata.update({\n",
    "                    \"source\": filename,\n",
    "                    \"permission\": permission,\n",
    "                    \"file_type\": file_type\n",
    "                })\n",
    "                self.processed_chunks.append(chunk)\n",
    "\n",
    "            print(f\"  -> {file_type.upper()} işlendi: {len(chunks)} parça. (Yetki: {permission})\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  !! Hata ({file_type} - {os.path.basename(file_path)}): {e}\")\n",
    "\n",
    "    def save_data(self, output_path):\n",
    "        with open(output_path, \"wb\") as f:\n",
    "            pickle.dump(self.processed_chunks, f)\n",
    "        print(f\"\\nToplam {len(self.processed_chunks)} chunk kaydedildi: {output_path}\")\n"
   ],
   "metadata": {
    "id": "wfEsKSFNYsdQ",
    "ExecuteTime": {
     "end_time": "2025-12-06T15:37:11.041705Z",
     "start_time": "2025-12-06T15:37:11.006553Z"
    }
   },
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "source": [
    "def main():\n",
    "    processor = DriveDocumentProcessor()\n",
    "    print(f\"Tarama Başlıyor: {BASE_PATH}\")\n",
    "\n",
    "    if not os.path.exists(BASE_PATH):\n",
    "        print(f\"HATA: Belirtilen yol bulunamadı! -> {BASE_PATH}\")\n",
    "\n",
    "        return\n",
    "\n",
    "    for folder in TARGET_FOLDERS:\n",
    "        folder_path = os.path.join(BASE_PATH, folder)\n",
    "        if not os.path.exists(folder_path):\n",
    "            print(f\"Uyarı: Klasör yok -> {folder}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n[{folder.upper()}] Klasörü Taranıyor...\")\n",
    "        files = os.listdir(folder_path)\n",
    "\n",
    "        for filename in files:\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            # Gizli dosyaları atla\n",
    "            if filename.startswith(\".\"): continue\n",
    "\n",
    "            # Dosya türüne göre işlem\n",
    "            if folder == \"excel\" and (filename.endswith(\".xlsx\") or filename.endswith(\".xls\")):\n",
    "                processor.process_excel(file_path)\n",
    "\n",
    "            elif folder == \"word\" and (filename.endswith(\".docx\") or filename.endswith(\".doc\")):\n",
    "                processor.process_word_detailed(file_path)\n",
    "\n",
    "            elif folder == \"pdf\" and filename.endswith(\".pdf\"):\n",
    "                processor.process_powerpoint_pdf(file_path, \"pdf\")\n",
    "\n",
    "            elif folder == \"powerpoint\" and (filename.endswith(\".pptx\") or filename.endswith(\".ppt\")):\n",
    "                processor.process_powerpoint_pdf(file_path, \"powerpoint\")\n",
    "\n",
    "    output_file = os.path.join(project_root, \"tum_dokumanlar_final_last.pkl\")\n",
    "\n",
    "    processor.save_data(output_file)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gw9Q2LqMZWt2",
    "outputId": "fd16959b-f1a7-49c2-c983-f5aefbc290e7",
    "ExecuteTime": {
     "end_time": "2025-12-06T15:37:18.760146Z",
     "start_time": "2025-12-06T15:37:11.721941Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tarama Başlıyor: C:\\mebi\\Tubitak_1505_Proje\\Doküman\n",
      "\n",
      "[PDF] Klasörü Taranıyor...\n",
      "  -> PDF işlendi: 5 parça. (Yetki: admin)\n",
      "  -> PDF işlendi: 22 parça. (Yetki: user)\n",
      "  -> PDF işlendi: 27 parça. (Yetki: admin)\n",
      "  -> PDF işlendi: 22 parça. (Yetki: admin)\n",
      "  -> PDF işlendi: 44 parça. (Yetki: user)\n",
      "  -> PDF işlendi: 51 parça. (Yetki: user)\n",
      "  -> PDF işlendi: 13 parça. (Yetki: user)\n",
      "  -> PDF işlendi: 111 parça. (Yetki: user)\n",
      "  -> PDF işlendi: 24 parça. (Yetki: user)\n",
      "  -> PDF işlendi: 53 parça. (Yetki: manager)\n",
      "  -> PDF işlendi: 67 parça. (Yetki: user)\n",
      "  -> PDF işlendi: 36 parça. (Yetki: user)\n",
      "  -> PDF işlendi: 8 parça. (Yetki: admin)\n",
      "  -> PDF işlendi: 14 parça. (Yetki: user)\n",
      "  -> PDF işlendi: 5 parça. (Yetki: user)\n",
      "  -> PDF işlendi: 7 parça. (Yetki: admin)\n",
      "  -> PDF işlendi: 3 parça. (Yetki: user)\n",
      "  -> PDF işlendi: 7 parça. (Yetki: user)\n",
      "  -> PDF işlendi: 5 parça. (Yetki: user)\n",
      "  -> PDF işlendi: 15 parça. (Yetki: user)\n",
      "  -> PDF işlendi: 3 parça. (Yetki: user)\n",
      "  -> PDF işlendi: 3 parça. (Yetki: user)\n",
      "  -> PDF işlendi: 2 parça. (Yetki: user)\n",
      "  -> PDF işlendi: 2 parça. (Yetki: user)\n",
      "  -> PDF işlendi: 2 parça. (Yetki: user)\n",
      "  -> PDF işlendi: 2 parça. (Yetki: user)\n",
      "  -> PDF işlendi: 4 parça. (Yetki: user)\n",
      "  -> PDF işlendi: 4 parça. (Yetki: user)\n",
      "  -> PDF işlendi: 6 parça. (Yetki: user)\n",
      "  -> PDF işlendi: 26 parça. (Yetki: admin)\n",
      "  -> PDF işlendi: 5 parça. (Yetki: user)\n",
      "  -> PDF işlendi: 9 parça. (Yetki: user)\n",
      "  -> PDF işlendi: 4 parça. (Yetki: user)\n",
      "\n",
      "[EXCEL] Klasörü Taranıyor...\n",
      "  -> Excel Tablo formatında işlendi: Aylik_Satis_Ozet_Ornek_Sablon.xlsx (1 sayfa)\n",
      "  -> Excel Tablo formatında işlendi: Bilimp_Fiyat_Listesi_Ornek_Sablon.xlsx (1 sayfa)\n",
      "  -> Excel Tablo formatında işlendi: Bilimp_Fiyat_Listesi_Ornek_Sablon2.xlsx (1 sayfa)\n",
      "\n",
      "[WORD] Klasörü Taranıyor...\n",
      "  -> Word detaylı işlendi: Butce_Ve_Maliyet_Raporu.docx\n",
      "  -> Word detaylı işlendi: Gizli_Erisim_Bilgileri.docx\n",
      "  -> Word detaylı işlendi: Haftalik_Yemek_Listesi.docx\n",
      "  -> Word detaylı işlendi: Teknik_Sartname_Taslak.docx\n",
      "\n",
      "[POWERPOINT] Klasörü Taranıyor...\n",
      "  -> POWERPOINT işlendi: 3 parça. (Yetki: user)\n",
      "\n",
      "Toplam 640 chunk kaydedildi: C:\\mebi\\Tubitak_1505_Proje\\tum_dokumanlar_final_last.pkl\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T15:12:52.586049Z",
     "start_time": "2025-12-06T15:12:52.580916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "print(\"Yüklü Sürüm:\", torch.__version__)\n",
    "# Çıktıda '+cpu' YERİNE '+cu121' yazmalı.\n",
    "\n",
    "print(\"CUDA Var mı?:\", torch.cuda.is_available())\n",
    "# Burası artık True olmalı."
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yüklü Sürüm: 2.8.0+cpu\n",
      "CUDA Var mı?: False\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ]
}
